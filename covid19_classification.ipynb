{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "covid19_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qDVEOfiAs7XE"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gXIbO0LYnURD"
   },
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2rPEjNYI3K7"
   },
   "source": [
    "# Clone Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQS6zsgktf4s",
    "outputId": "0aca843f-8a5f-441a-87f4-40773ee5aefd"
   },
   "source": [
    "! git clone https://github.com/education454/datasets.git"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'datasets'...\n",
      "remote: Enumerating objects: 2301, done.\u001B[K\n",
      "remote: Total 2301 (delta 0), reused 0 (delta 0), pack-reused 2301\u001B[K\n",
      "Receiving objects: 100% (2301/2301), 1.31 GiB | 36.20 MiB/s, done.\n",
      "Checking out files: 100% (2295/2295), done.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hctsjRzUytc8"
   },
   "source": [
    "base_dir = '/content/datasets/Data'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "train_covid_dir = os.path.join(train_dir, 'COVID19')\n",
    "train_normal_dir = os.path.join(train_dir, 'NORMAL')\n",
    "\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "test_covid_dir = os.path.join(test_dir, 'COVID19')\n",
    "test_normal_dir = os.path.join(test_dir, 'NORMAL')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o_0CYO_x4bMu",
    "outputId": "0abace3b-135c-479b-865f-4409172cd6ac"
   },
   "source": [
    "train_covid_names = os.listdir(train_covid_dir)\n",
    "print(train_covid_names[:10])\n",
    "\n",
    "train_normal_names = os.listdir(train_normal_dir)\n",
    "print(train_normal_names[:10])\n",
    "\n",
    "test_covid_names = os.listdir(test_covid_dir)\n",
    "print(test_covid_names[:10])\n",
    "\n",
    "test_normal_names = os.listdir(test_normal_dir)\n",
    "print(test_normal_names[:10])"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['COVID19(381).jpg', 'COVID19(273).jpg', 'COVID19(137).jpg', 'COVID19(213).jpg', 'COVID19(480).jpg', 'COVID19(87).jpg', 'COVID19(401).jpg', 'COVID19(543).jpg', 'COVID19(475).jpg', 'COVID19(120).jpg']\n",
      "['NORMAL(1401).jpg', 'NORMAL(35).jpg', 'NORMAL(148).jpg', 'NORMAL(198).jpg', 'NORMAL(268).jpg', 'NORMAL(19).jpg', 'NORMAL(25).jpg', 'NORMAL(1192).jpg', 'NORMAL(426).jpg', 'NORMAL(506).jpg']\n",
      "['COVID-19 (718).jpg', 'COVID19(200).jpg', 'COVID19(463).jpg', 'COVID19(315).jpg', 'COVID19(561).jpg', 'COVID19(450).jpg', 'COVID19(186).jpg', 'COVID19(426).jpg', 'COVID-19 (587).jpg', 'COVID-19 (789).jpg']\n",
      "['NORMAL(632).jpg', 'NORMAL(327).jpg', 'NORMAL(687).jpg', 'NORMAL(1301).jpg', 'NORMAL(329).jpg', 'NORMAL(484).jpg', 'NORMAL(455).jpg', 'NORMAL(18).jpg', 'NORMAL(155).jpg', 'NORMAL(187).jpg']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WMy0K85v58tN",
    "outputId": "4a8a5172-3e5b-4f1a-91bf-0f8846c1ab7f"
   },
   "source": [
    "print('Train Dataset Covid Images:', len(train_covid_names))\n",
    "print('Train Dataset Normal Images:', len(train_normal_names))\n",
    "\n",
    "print('Test Dataset Covid Images:', len(test_covid_names))\n",
    "print('Test Dataset Normal Images:', len(test_normal_names))\n",
    "\n",
    "print('Total Train Images:', len(train_covid_names + train_normal_names))\n",
    "print('Total Test Images:', len(test_covid_names + test_normal_names))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Dataset Covid Images: 545\n",
      "Train Dataset Normal Images: 1266\n",
      "Test Dataset Covid Images: 167\n",
      "Test Dataset Normal Images: 317\n",
      "Total Train Images: 1811\n",
      "Total Test Images: 484\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csQySlucX_6E"
   },
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set the number of columns and rows\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "# set the figure size\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12, 12)\n",
    "\n",
    "# get the filenames from the covid & normal dir of the train dataset\n",
    "next_covid_pic = [os.path.join(train_covid_dir, fname) for fname in train_covid_names[0:8]]\n",
    "next_normal_pic = [os.path.join(train_normal_dir, fname) for fname in train_normal_names[0:8]]\n",
    "\n",
    "# print the list\n",
    "print(next_covid_pic)\n",
    "print(next_normal_pic)\n",
    "\n",
    "for i, img_path in enumerate(next_covid_pic + next_normal_pic):\n",
    "  data = img_path.split('/', 6)[6]\n",
    "  sp = plt.subplot(nrows, ncols, i+1)\n",
    "  sp.axis('off')\n",
    "  img = mpimg.imread(img_path)\n",
    "  sp.set_title(data, fontsize=10)\n",
    "  plt.imshow(img, cmap='gray')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generating Training , Validation & Testing Batches"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    validation_split = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, \n",
    "    target_size = (150,150),\n",
    "    subset = 'training',\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (150,150),\n",
    "    subset = 'validation',\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir, \n",
    "    target_size = (150,150),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "display(train_generator.class_indices)\n",
    "\n",
    "display(test_generator.class_indices)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build CNN Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# add the convolutional layer\n",
    "# filters, size of filters, padding, activation_function, input_shape\n",
    "model.add(Conv2D(32, (5,5), padding='SAME', activation='relu', input_shape=(150, 150, 3)))\n",
    "\n",
    "# pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# place a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# add another conv. layer\n",
    "model.add(Conv2D(64, (5,5), padding='SAME', activation='relu'))\n",
    "\n",
    "# pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# place a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Flatten the image to 1 dimensional array\n",
    "model.add(Flatten())\n",
    "\n",
    "# add a dense layer: amount of nodes, activation\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "# place a dropout layer\n",
    "# 0.5 drop out rate is recommended, half input nodes will be dropped at each update\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# output layer :D\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compile & Train Model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=10\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history.history.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('epoch')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_acc}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test your model with some images from your local computer to predict whether a patient is affected by COVID19 or not.\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "\n",
    "uploaded = files.upload()\n",
    "for fn in uploaded.keys():\n",
    "  path='/content/'+fn\n",
    "  print(path)\n",
    "  img = image.load_img(path , target_size=(150,150))\n",
    "  x = image.img_to_array(img)\n",
    "  x=np.expand_dims(x,axis=0)\n",
    "  images = np.vstack([x])\n",
    "  classes = model.predict(images,batch_size=10)\n",
    "  print(fn)\n",
    "  if classes==0:\n",
    "    print('Covid19')\n",
    "  else:\n",
    "    print('Normal')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save('covid19_classification')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!zip -r covid19_classification.zip covid19_classification/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    ""
   ],
   "metadata": {
    "id": "FHWVDdo3dJeF"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}